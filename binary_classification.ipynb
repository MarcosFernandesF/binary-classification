{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a38e2a6",
   "metadata": {},
   "source": [
    "# Problema 23 - Application Incident Prediction\n",
    "\n",
    "## Pré-processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e514ee61",
   "metadata": {},
   "source": [
    "### Carregando os dados e realizando limpeza inicial. ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38732882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset carregado. Dimensões: (54745, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_name</th>\n",
       "      <th>response_time</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>cpu_usage</th>\n",
       "      <th>memory_usage</th>\n",
       "      <th>disk_space</th>\n",
       "      <th>active_users</th>\n",
       "      <th>downtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NIP</td>\n",
       "      <td>22</td>\n",
       "      <td>61</td>\n",
       "      <td>32</td>\n",
       "      <td>42</td>\n",
       "      <td>52</td>\n",
       "      <td>12000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NIP</td>\n",
       "      <td>21</td>\n",
       "      <td>63</td>\n",
       "      <td>31</td>\n",
       "      <td>41</td>\n",
       "      <td>51</td>\n",
       "      <td>11000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NIP</td>\n",
       "      <td>20</td>\n",
       "      <td>98</td>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NIP</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>29</td>\n",
       "      <td>39</td>\n",
       "      <td>49</td>\n",
       "      <td>9000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NIP</td>\n",
       "      <td>18</td>\n",
       "      <td>67</td>\n",
       "      <td>28</td>\n",
       "      <td>38</td>\n",
       "      <td>48</td>\n",
       "      <td>8000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  app_name  response_time  error_rate  cpu_usage  memory_usage  disk_space  \\\n",
       "0      NIP             22          61         32            42          52   \n",
       "1      NIP             21          63         31            41          51   \n",
       "2      NIP             20          98         30            40          50   \n",
       "3      NIP             19          15         29            39          49   \n",
       "4      NIP             18          67         28            38          48   \n",
       "\n",
       "   active_users  downtime  \n",
       "0         12000         1  \n",
       "1         11000         0  \n",
       "2         10000         0  \n",
       "3          9000         0  \n",
       "4          8000         0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importando bibliotecas necessárias\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Carregando o dataset\n",
    "df = pd.read_csv('app_incident_report.csv')\n",
    "\n",
    "# Removendo a coluna 'incident_duration' conforme especificado no enunciado\n",
    "df = df.drop('incident_duration', axis=1)\n",
    "\n",
    "print(\"Dataset carregado. Dimensões:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6beb8ae",
   "metadata": {},
   "source": [
    "### Analisar se é necessário remover a coluna `app_name`\n",
    "\n",
    "Olhando os dados por cima notei que o app_name é sempre o mesmo, então nesse passo vamos verificar quantos valores únicos existem na coluna `app_name`. Se houver apenas um, a coluna é constante e não contribui com informação para o modelo, podendo ser removida com segurança."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6406aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de valores únicos em 'app_name': 1\n",
      "\n",
      "Contagem de cada valor:\n",
      "app_name\n",
      "NIP    54745\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Conclusão: A coluna 'app_name' possui um valor constante e será removida.\n"
     ]
    }
   ],
   "source": [
    "# Verificando os valores únicos em 'app_name'\n",
    "unique_apps = df['app_name'].nunique()\n",
    "app_counts = df['app_name'].value_counts()\n",
    "\n",
    "print(f\"Número de valores únicos em 'app_name': {unique_apps}\")\n",
    "print(\"\\nContagem de cada valor:\")\n",
    "print(app_counts)\n",
    "\n",
    "if unique_apps == 1:\n",
    "    print(\"\\nConclusão: A coluna 'app_name' possui um valor constante e será removida.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fadda8",
   "metadata": {},
   "source": [
    "### Separação de Características (X) e Alvo (y)\n",
    "\n",
    "Separando o dataset em Características (features) e Alvo (target):\n",
    "* **X**: Todas as colunas de características que usaremos para treinar o modelo.\n",
    "* **y**: A coluna alvo que queremos prever (`downtime`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dac1fb9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape de X (features): (54745, 6)\n",
      "Shape de y (target): (54745,)\n"
     ]
    }
   ],
   "source": [
    "# Separando as features (X) e o target (y)\n",
    "X = df.drop(['downtime', 'app_name'], axis=1)\n",
    "y = df['downtime']\n",
    "\n",
    "print(\"Shape de X (features):\", X.shape)\n",
    "print(\"Shape de y (target):\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6ee83e",
   "metadata": {},
   "source": [
    "### Análise da Variável Alvo (`downtime`)\n",
    "\n",
    "Pela análise visual foi possível ver que a distribuição da variável `downtime` é completamente\n",
    "desbalanceada. Esse desbalanceamento pode ser preocupante na hora da divisão dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eaa4506f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contagem de cada classe:\n",
      "downtime\n",
      "0    54197\n",
      "1      548\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Porcentagem de cada classe:\n",
      "downtime\n",
      "0    98.998995\n",
      "1     1.001005\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculando a contagem e a proporção de cada classe\n",
    "downtime_counts = y.value_counts()\n",
    "downtime_percentage = y.value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"Contagem de cada classe:\")\n",
    "print(downtime_counts)\n",
    "print(\"\\nPorcentagem de cada classe:\")\n",
    "print(downtime_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9cafc1",
   "metadata": {},
   "source": [
    "### Divisão em Dados de Treino e Teste\n",
    "\n",
    "Será separado 20% dos dados para teste.\n",
    "\n",
    "Como **demonstrado na análise acima**, a classe `downtime=1` é bem rara (correspondendo a aproximadamente **1%** dos dados). Por isso, é necessário usar o parâmetro `stratify=y`. Essa estratificação garante que a proporção de downtime seja mantida tanto para o conjunto de treino quanto para o de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bacf231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Shapes após a divisão ---\n",
      "X_train: (43796, 6)\n",
      "X_test: (10949, 6)\n",
      "y_train: (43796,)\n",
      "y_test: (10949,)\n",
      "\n",
      "--- Verificação da estratificação ---\n",
      "Proporção de downtime no y_train: 0.010000913325417846\n",
      "Proporção de downtime no y_test: 0.010046579596310166\n"
     ]
    }
   ],
   "source": [
    "# Dividindo os dados com test_size=0.2 (20%) e estratificação\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"--- Shapes após a divisão ---\")\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"X_test:\", X_test.shape)\n",
    "print(\"y_train:\", y_train.shape)\n",
    "print(\"y_test:\", y_test.shape)\n",
    "\n",
    "print(\"\\n--- Verificação da estratificação ---\")\n",
    "print(\"Proporção de downtime no y_train:\", y_train.value_counts(normalize=True).values[1])\n",
    "print(\"Proporção de downtime no y_test:\", y_test.value_counts(normalize=True).values[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b67f96",
   "metadata": {},
   "source": [
    "### Escalonamento das Características\n",
    "\n",
    "As colunas numéricas têm escalas muito diferentes. Por exemplo, active_users vai de 0 a 12.000, enquanto cpu_usage vai de 20 a 32.\n",
    "Portanto, será utilizado o `StandardScaler` para padronizar os dados (média 0 e desvio padrão 1).\n",
    "\n",
    "**Importante:** O `StandardScaler` é \"treinado\" (`fit`) **apenas** com os dados de treino para evitar vazamento de informação dos dados de teste. Depois, ele é usado para transformar (`transform`) ambos os conjuntos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09e65ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amostra dos dados de treino após o escalonamento:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response_time</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>cpu_usage</th>\n",
       "      <th>memory_usage</th>\n",
       "      <th>disk_space</th>\n",
       "      <th>active_users</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.574671</td>\n",
       "      <td>-0.578807</td>\n",
       "      <td>0.574671</td>\n",
       "      <td>0.574671</td>\n",
       "      <td>0.574671</td>\n",
       "      <td>0.574671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.147714</td>\n",
       "      <td>0.596261</td>\n",
       "      <td>1.147714</td>\n",
       "      <td>1.147714</td>\n",
       "      <td>1.147714</td>\n",
       "      <td>1.147714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.717498</td>\n",
       "      <td>-1.131780</td>\n",
       "      <td>-1.717498</td>\n",
       "      <td>-1.717498</td>\n",
       "      <td>-1.717498</td>\n",
       "      <td>-1.717498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001629</td>\n",
       "      <td>-0.820733</td>\n",
       "      <td>0.001629</td>\n",
       "      <td>0.001629</td>\n",
       "      <td>0.001629</td>\n",
       "      <td>0.001629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001629</td>\n",
       "      <td>-1.028098</td>\n",
       "      <td>0.001629</td>\n",
       "      <td>0.001629</td>\n",
       "      <td>0.001629</td>\n",
       "      <td>0.001629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   response_time  error_rate  cpu_usage  memory_usage  disk_space  \\\n",
       "0       0.574671   -0.578807   0.574671      0.574671    0.574671   \n",
       "1       1.147714    0.596261   1.147714      1.147714    1.147714   \n",
       "2      -1.717498   -1.131780  -1.717498     -1.717498   -1.717498   \n",
       "3       0.001629   -0.820733   0.001629      0.001629    0.001629   \n",
       "4       0.001629   -1.028098   0.001629      0.001629    0.001629   \n",
       "\n",
       "   active_users  \n",
       "0      0.574671  \n",
       "1      1.147714  \n",
       "2     -1.717498  \n",
       "3      0.001629  \n",
       "4      0.001629  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criando o objeto scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Treinando o scaler com os dados de treino e transformando-os\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Aplicando a mesma transformação aos dados de teste\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convertendo de volta para DataFrame para visualização (opcional)\n",
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "\n",
    "print(\"Amostra dos dados de treino após o escalonamento:\")\n",
    "X_train_scaled_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f04746",
   "metadata": {},
   "source": [
    "### Conclusão do Pré-processamento\n",
    "\n",
    "Os seguintes conjuntos de dados estão preparados:\n",
    "\n",
    "* `X_train_scaled`, `y_train`: Para treinar os modelos.\n",
    "* `X_test_scaled`, `y_test`: Para testar os modelos e gerar os resultados finais."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
